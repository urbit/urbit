page changes -> mark as dirty -> write page eventually -> mark clean
can check beforehand but branching per write, or do exception-y things
hence segfaults -> trap, mark dirty -> go back to work
mprotect loom whenever a snapshot is written so the next time someone writes
we can segfault, mark as dirty, un mprotect, and move on with life.

Joshin = ~silsyn-wathep, person to talk to about runtime stuff

introductory runtime task: cache reclamation for compiled nock programs
when we run nock, we had a tree talking interpreter for a while
now when we see a formula, compile to bytecode + compile, store in hashtable
(map original-formula compiled-bytecode)
subsequent formulas just get looked up.

this hashtable (formula to program) grows to be "every formula we run"
this isn't without bound since it's rare to dynamically create formulas (unless
we get them over the network as OTAs).
olden days: hashtable grew without bound as OTAs happened, disaster.
now: every 1k events, clear the cache. we can surely be smarter.

LRU would be improvement, LFU too, CLOCK algorithm (look this up)
for our hashtables there is a CLOCK algorithm, already implemented in the hoon
compiler! after ~50k entries it drops with CLOCK.

problem: freeing fcn asssumes it's a noun. free atom directly, cell free
entries, etc. this is a bytecode (some C struct)

parameterize the hashtable with some sort of "freeing" function -> problem solved?
current impl of freeing: traverses the hashtable, traversal frees elements.
then we free the map itself.

nock.c: u3n_free() does this

u3a_noun: noun struct
u3_noun is a 32bit "pointer". if high bit not set, it's a direct atom.
u3_noun + loom offset == pointer to u3a_noun

u3a_noun implicit union between u3a_atom and u3a_cellS
to tell what it is, need a u3_noun pointer - second highest bit tells this
0 for ptr, 1 for cell. see u3a_is_atom

u3a_noun always in a u3a_box
box has size on both sides, and a refcount (use_w)
so bytecode program - 1 gives you use_w, the refcount!

[ ] find CLOCK algo somwhere, u3h_trim_to
  clock is always pointing at the next thing to remove

so now what should u3n_free actually do?
maybe drop half the cache? divide by 2 and add 1 I guess?
or just divide by 2, not freeing from a size 1 map doesn't really matter.

but what is the "hank cache"? must also be freed?


serf calls u3m_reclaim() when rec_o is true. few reasons for that
|reset == new kernel, toss everything
memory pressure, toss everything
1000 events, maybe don't toss entire bytecode cache

every time we add something to the hashtable resize?
nvm doesn't work - whenever you do throw away anything you need to throw
away all the callsite caches.
"hank caches" == callsite caches

each hank has a u3j_site, each site refers to a u3n_prog. don't want to keep
these around if we've cleared the u3n_prog from the cache.


foo-take: when leaving inner road, "take" whatever's returned and bring it
up to the outer road.

own_o: if false, could mean bytecode is owned in outer road. similar to fon_o
for finks.

byc_u doesn't have to be freed - allocated in same box as others
see difference between _n_prog_old and _n_prog_new

[ ] pick some constant to cut the cache size to.
[ ] add comment to u3j_reclaim header indicating that it's called from
    u3n_reclaim. Then just do that.
[ ] think about maybe making freeing function a part of u3h_root

testing:
CI will be good
run ship for a bit, run |mass from time to time (chokes on memory leak)
put log in branch that doesn't toss everything, have it print the size
after the reclamation (use_w from the root)

change zuse.hoon (or hoon.hoon) and recompile, see what happens to the cache
sizes and if they're being cleared properly

running |mass can also give a pretty good idea of the real size of the cache
u3h_count and u3h_discount (run discount after count to reset marks)
can count noun (kernel state), then count hashtable, then discount to get counts
for just the hashtable. more than just the u3h flavors (i.e. u3a, u3j, etc.)
